{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Swift4TF_MNIST.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Swift",
      "language": "swift",
      "name": "swift"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuzYtyiH_jxK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import Foundation\n",
        "import TensorFlow\n",
        "import Python"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQm7jGRsWgDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "let subprocess = Python.import(\"subprocess\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FU5Vko57dWnZ",
        "colab_type": "text"
      },
      "source": [
        "## Download Data and Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nU-JcQQabi5O",
        "colab_type": "code",
        "outputId": "654a7d8c-18f8-4b32-e19f-8e3b5e121c04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "let urllib = Python.import(\"urllib.request\")\n",
        "let fileBaseURL = \"https://raw.githubusercontent.com/tensorflow/swift-models/master/Datasets/MNIST/\"\n",
        "let files = [\"train-images-idx3-ubyte\", \"train-labels-idx1-ubyte\"]\n",
        "\n",
        "for file in files {\n",
        "  let command = \"wget \"+fileBaseURL+file\n",
        "  //print(fileBaseURL+files[1])\n",
        "  subprocess.call(command, shell: true)\n",
        "}"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-13 15:58:54--  https://raw.githubusercontent.com/tensorflow/swift-models/master/Datasets/MNIST/train-images-idx3-ubyte\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 47040016 (45M) [application/octet-stream]\n",
            "Saving to: ‘train-images-idx3-ubyte’\n",
            "\n",
            "train-images-idx3-u 100%[===================>]  44.86M   194MB/s    in 0.2s    \n",
            "\n",
            "2019-06-13 15:59:00 (194 MB/s) - ‘train-images-idx3-ubyte’ saved [47040016/47040016]\n",
            "\n",
            "--2019-06-13 15:59:00--  https://raw.githubusercontent.com/tensorflow/swift-models/master/MNIST/train-labels-idx1-ubyte\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 60008 (59K) [application/octet-stream]\n",
            "Saving to: ‘train-labels-idx1-ubyte’\n",
            "\n",
            "train-labels-idx1-u 100%[===================>]  58.60K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2019-06-13 15:59:00 (2.92 MB/s) - ‘train-labels-idx1-ubyte’ saved [60008/60008]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gF303ze8dxXv",
        "colab_type": "text"
      },
      "source": [
        "## Process Data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dthLi1e191dQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "var batchSize:Int = 32 \n",
        "\n",
        "/// Reads a file into an array of bytes.\n",
        "func readFile(_ path: String) -> [UInt8] {\n",
        "    let url = URL(fileURLWithPath: path)\n",
        "    let data = try! Data(contentsOf: url, options: [])\n",
        "    return [UInt8](data)\n",
        "}\n",
        "\n",
        "/// Reads MNIST images and labels from specified file paths.\n",
        "func readMNIST(imagesFile: String, labelsFile: String) -> (images: Tensor<Float>,\n",
        "                                                           labels: Tensor<Int32>) {\n",
        "    print(\"Reading data.\")\n",
        "    let images = readFile(imagesFile).dropFirst(16).map(Float.init)\n",
        "    let labels = readFile(labelsFile).dropFirst(8).map(Int32.init)\n",
        "    let rowCount = Int(labels.count)\n",
        "    let imageHeight: Int = 28, imageWidth: Int = 28\n",
        "\n",
        "    print(\"Constructing data tensors.\")\n",
        "    return (\n",
        "        images: Tensor(shape: [rowCount, 1, imageHeight, imageWidth], scalars: images)\n",
        "            .transposed(withPermutations: [0, 2, 3, 1]) / 255, // NHWC\n",
        "        labels: Tensor(labels)\n",
        "    )\n",
        "}\n",
        "\n",
        "/// Split data into training and test\n",
        "func splitTrainTest(data: Tensor<Float>, labels: Tensor<Int32>) -> (Tensor<Float>, Tensor<Int32>, Tensor<Float> , Tensor<Int32>) {\n",
        "  \n",
        "  let N = Int(data.shape[0])\n",
        "  let split = Int(0.8 * Float(N))\n",
        "  \n",
        "  let trainX = data[0..<split]\n",
        "  let trainY = labels[0..<split]\n",
        "  \n",
        "  let testX = data[split..<N]\n",
        "  let testY = labels[split..<N]\n",
        "  \n",
        "  return (trainX, trainY, testX, testY)\n",
        "}\n",
        "\n",
        "/// Extract a batch of certain size \n",
        "func minibatch<Scalar>(in x: Tensor<Scalar>, at index: Int) -> Tensor<Scalar> {\n",
        "    let start = Int(index * batchSize)\n",
        "    return x[start..<start+Int(batchSize)]\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4J6Aq5jU936Z",
        "colab_type": "code",
        "outputId": "6c1d758e-dc8d-4933-ecdf-a355d9ea62fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "// convert into tensors\n",
        "let (data, trainNumericLabels) = readMNIST(imagesFile: files[0], labelsFile: files[1])\n",
        "let labels = Tensor<Int32>(trainNumericLabels)\n",
        "\n",
        "// split into training and testing \n",
        "let (trainX, trainY, testX, testY) = splitTrainTest(data: data, labels: labels)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading data.\n",
            "Constructing data tensors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgBo0BC7d7bg",
        "colab_type": "text"
      },
      "source": [
        "## CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZ-tLhdlJvc2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "struct CNN: Layer {\n",
        "  \n",
        "    typealias Input = Tensor<Float>\n",
        "    typealias Output = Tensor<Float>\n",
        "  \n",
        "    var conv1 = Conv2D<Float>(filterShape: (3, 3, 1, 16), activation: relu) \n",
        "    var conv2 = Conv2D<Float>(filterShape: (3, 3, 16, 32), activation: relu) \n",
        " \n",
        "    var pool = MaxPool2D<Float>(poolSize: (2, 2), strides: (2, 2))\n",
        "  \n",
        "    var flatten = Flatten<Float>()\n",
        "  \n",
        "    var dense1 = Dense<Float>(inputSize: 5*5*32 , outputSize: 128, activation: tanh)\n",
        "    var dense2 = Dense<Float>(inputSize: 128 , outputSize: 10)\n",
        "\n",
        "    @differentiable\n",
        "    func call(_ input: Input) -> Output {\n",
        "        let convolved = input.sequenced(through: conv1, pool, conv2, pool)\n",
        "        return convolved.sequenced(through:flatten, dense1, dense2)\n",
        "    }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDES_rECKXTk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "// report accuracy of a batch \n",
        "func getAccuracy(y:Tensor<Int32>, logits:Tensor<Float>) -> Float{\n",
        "  let out  = Tensor<Int32>(logits.argmax(squeezingAxis: 1) .== y).sum().scalarized()\n",
        "  return Float(out) / Float(y.shape[0])\n",
        "}\n",
        "\n",
        "//round two decimal places \n",
        "func roundTwo(_ input:Float) -> Float{\n",
        "  return (input*100).rounded()/100\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWqvb0u3ZAIg",
        "colab_type": "code",
        "outputId": "adcdc3f0-0186-4bc2-e8b6-f8532de6a018",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "var model = CNN()\n",
        "let optimizer = Adam(for: model)\n",
        "\n",
        "//warmup \n",
        "let tensor = Tensor<Float>(zeros: [1, 28, 28, 1])\n",
        "print(model(tensor))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lV2RzLtMeBBH",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzK9FPV3daq5",
        "colab_type": "code",
        "outputId": "20edcfb2-daf4-429b-eb3a-c586d8fef16d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "let stepsInEpoch:Int = Int(Float(testX.shape[0]) / Float(batchSize))\n",
        "var trainLoss:Float = 0.0\n",
        "var trainAcc :Float = 0.0\n",
        "var testLoss:Float = 0.0\n",
        "var testAcc:Float = 0.0 \n",
        "\n",
        "var batchCount: Float = 0.0\n",
        "for epoch in 0...4{\n",
        "  \n",
        "  //evaluate metrics\n",
        "  trainLoss = 0.0\n",
        "  trainAcc  = 0.0\n",
        "  batchCount = 0.0\n",
        "    \n",
        "  for i in 0..<stepsInEpoch {\n",
        "  \n",
        "    //get batches\n",
        "    let X = minibatch(in: trainX, at: i)\n",
        "    let y = minibatch(in: trainY, at: i)\n",
        "\n",
        "    //calculate the loss and gradient\n",
        "    let (loss, grads) = valueWithGradient(at: model) { model -> Tensor<Float> in\n",
        "            let logits = model(X)\n",
        "            return softmaxCrossEntropy(logits: logits, labels: y)\n",
        "    }\n",
        "\n",
        "    //make an optimizer step \n",
        "    optimizer.update(&model.allDifferentiableVariables, along: grads)    \n",
        "    \n",
        "    let logits = model(X) //this is slowing down ? \n",
        "    let acc = getAccuracy(y:y, logits:logits)\n",
        "    \n",
        "    trainLoss += Float(loss.scalarized())\n",
        "    trainAcc  += acc\n",
        "    batchCount += 1\n",
        "  }\n",
        "  \n",
        "  trainLoss /= batchCount\n",
        "  trainAcc  /= batchCount\n",
        " \n",
        "  //training\n",
        "  testLoss = 0.0\n",
        "  testAcc  = 0.0\n",
        "  \n",
        "  let logits = model(testX)\n",
        "  let loss = softmaxCrossEntropy(logits: logits, labels: testY)\n",
        "  let acc = getAccuracy(y:testY, logits:logits)\n",
        "\n",
        "  testLoss += Float(loss.scalarized())\n",
        "  testAcc  += acc\n",
        "  print(\"epoch: \\(epoch+1), train_loss: \\(roundTwo(trainLoss)), test_loss: \\(roundTwo(testLoss)), train_acc: \\(roundTwo(trainAcc)), test_acc: \\(roundTwo(testAcc))\" )\n",
        "}"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1, train_loss: 0.35, test_loss: 0.16, train_acc: 0.92, test_acc: 0.95\n",
            "epoch: 2, train_loss: 0.1, test_loss: 0.12, train_acc: 0.97, test_acc: 0.96\n",
            "epoch: 3, train_loss: 0.06, test_loss: 0.09, train_acc: 0.99, test_acc: 0.97\n",
            "epoch: 4, train_loss: 0.04, test_loss: 0.08, train_acc: 0.99, test_acc: 0.98\n",
            "epoch: 5, train_loss: 0.03, test_loss: 0.07, train_acc: 1.0, test_acc: 0.98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5UpckxEsqNO",
        "colab_type": "text"
      },
      "source": [
        "License https://github.com/tensorflow/swift-models/blob/stable/LICENSE"
      ]
    }
  ]
}
